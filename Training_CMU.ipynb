{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import ast\n",
    "import cv2\n",
    "import json\n",
    "import network as net\n",
    "import math\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 356\n",
    "network_output = 44\n",
    "def make_batch(img_path, anno_data, batch_size = 16):\n",
    "    num_of_data = len(img_path)\n",
    "    index = np.arange(0, num_of_data)\n",
    "    np.random.shuffle(index)\n",
    "    index = index[:batch_size]\n",
    "    \n",
    "    shuffled_img_data = [img_path[i] for i in index]\n",
    "    shuffled_anno_data = [anno_data[j] for j in index]\n",
    "    \n",
    "    return np.asarray(shuffled_img_data), np.asarray(shuffled_anno_data)\n",
    "def make_test_batch(img_path, batch_size = 16):\n",
    "    num_of_data = len(img_path)\n",
    "    index = np.arange(0, num_of_data)\n",
    "    np.random.shuffle(index)\n",
    "    index = index[:batch_size]\n",
    "    \n",
    "    shuffled_img_data = [img_path[i] for i in index]\n",
    "    \n",
    "    return np.asarray(shuffled_img_data)\n",
    "\n",
    "def path_to_image(img_path, batch_size):\n",
    "    #buffer 선언\n",
    "    image_data = np.zeros((batch_size, img_width, img_width, 3), np.uint8)\n",
    "    \n",
    "    index = 0\n",
    "    for img in (img_path):\n",
    "        #buffer = cv2.imread(img)\n",
    "        #buffer = cv2.resize(buffer, (526, 526))\n",
    "        #image_data[index] = buffer\n",
    "        #index = index + 1\n",
    "        #buffer = cv2.resize(buffer, (526, 526))\n",
    "\n",
    "        image_data[index] = cv2.imread(img)\n",
    "        index = index + 1\n",
    "\n",
    "    return image_data\n",
    "\n",
    "def _put_heatmap_on_plane(heatmap, plane_idx, joint, sigma, height, width, stride):\n",
    "    start = stride / 2.0 - 0.5\n",
    "\n",
    "    center_x, center_y = joint\n",
    "\n",
    "    for g_y in range(height):\n",
    "        for g_x in range(width):\n",
    "            x = start + g_x * stride\n",
    "            y = start + g_y * stride\n",
    "            d2 = (x-center_x) * (x-center_x) + (y-center_y) * (y-center_y)\n",
    "            exponent = d2 / 2.0 / sigma / sigma\n",
    "            if exponent > 4.6052:\n",
    "                continue\n",
    "\n",
    "            heatmap[g_y, g_x, plane_idx] += math.exp(-exponent)\n",
    "            if heatmap[g_y, g_x, plane_idx] > 1.0:\n",
    "                heatmap[g_y, g_x, plane_idx] = 1.0\n",
    "                \n",
    "                \n",
    "def _put_paf_on_plane(vectormap, countmap, plane_idx, center_from, center_to, threshold, height, width, stride):\n",
    "    center_from = (center_from[0] // stride, center_from[1] // stride)\n",
    "    center_to = (center_to[0] // stride, center_to[1] // stride)\n",
    "\n",
    "    vec_x = center_to[0] - center_from[0]\n",
    "    vec_y = center_to[1] - center_from[1]\n",
    "\n",
    "    min_x = max(0, int(min(center_from[0], center_to[0]) - threshold))\n",
    "    min_y = max(0, int(min(center_from[1], center_to[1]) - threshold))\n",
    "\n",
    "    max_x = min(width, int(max(center_from[0], center_to[0]) + threshold))\n",
    "    max_y = min(height, int(max(center_from[1], center_to[1]) + threshold))\n",
    "\n",
    "    norm = math.sqrt(vec_x ** 2 + vec_y ** 2)\n",
    "    if norm < 1e-8: #1e-8 이하는 0으로 인식되서 0으로 나눌수 없다는 에러 발생. 따라서 return처리 해줌\n",
    "        return\n",
    "\n",
    "    vec_x /= norm\n",
    "    vec_y /= norm\n",
    "    \n",
    "    for x in range(min_x, max_x):\n",
    "        for y in range(min_y, max_y):\n",
    "            bec_x = x - center_from[0]\n",
    "            bec_y = y - center_from[1]\n",
    "            dist = abs(bec_x * vec_y - bec_y * vec_x)\n",
    "\n",
    "            if dist > threshold:\n",
    "                continue\n",
    "\n",
    "            countmap[x][y][plane_idx] = countmap[x][y][plane_idx] + 1\n",
    "\n",
    "            vectormap[x][y][plane_idx*2+0] = vec_x\n",
    "            vectormap[x][y][plane_idx*2+1] = vec_y\n",
    "            \n",
    "\n",
    "def bubble_sort(L):\n",
    "    for i in range(len(L)-1):\n",
    "        for j in range(len(L)-1):\n",
    "            if L[j] > L[j+1]:\n",
    "                temp = L[j+1]\n",
    "                L[j+1] = L[j]\n",
    "                L[j] = temp\n",
    "                \n",
    "def load_data():\n",
    "        path = \"./MPII_Dataset/annotation/mpii_human_pose_v1_u12_3.json\"\n",
    "        f = open(path)\n",
    "        s = f.readlines()\n",
    "\n",
    "        file_name = []\n",
    "        parts = []\n",
    "        _joint_data = []\n",
    "        \n",
    "        \n",
    "        img_path = \"./MPII_Dataset/images/\"#######\n",
    "        img_path2 = \"./MPII_Dataset/resized_images2/\"\n",
    "        file_path = []\n",
    "        file_path2 = []\n",
    "\n",
    "        for index, i in enumerate(s):\n",
    "\n",
    "            file_name_index = i.find(\"file_name\")\n",
    "            is_train_index = i.find(\"is_train\")\n",
    "            file_name.append(i[file_name_index + 13 :is_train_index - 4])\n",
    "\n",
    "\n",
    "            parts_index = i.find(\"parts\")\n",
    "            visibility_index = i.find(\"visibility\")\n",
    "            parts.append(i[parts_index + 8:visibility_index - 3])\n",
    "\n",
    "            joint_data = []\n",
    "            file_index, annotation_index = index, index\n",
    "            if(parts[index] == \"null\"):\n",
    "                joint_data.append(\"null\")\n",
    "                pass\n",
    "            else:\n",
    "                raw_data = ast.literal_eval(parts[annotation_index])\n",
    "                joint_data.append(raw_data)\n",
    "\n",
    "            _joint_data.append(joint_data)\n",
    "            index = index + 1\n",
    "        for i in file_name:\n",
    "            file_path.append(img_path + i)############\n",
    "            file_path2.append(img_path2 + i)\n",
    "\n",
    "        index2 = 0\n",
    "        heatmap_height = network_output\n",
    "        heatmap_width = network_output\n",
    "        for j in file_path:\n",
    "            img_data = cv2.imread(j)\n",
    "            height = (np.shape(img_data)[0])\n",
    "            width = (np.shape(img_data)[1])\n",
    "\n",
    "            if(_joint_data[index2][0] == 'null'):\n",
    "                #print(_joint_data[index2][0])\n",
    "                pass\n",
    "            else:\n",
    "                array = _joint_data[index2][0].keys()\n",
    "                for k in array:\n",
    "                    _joint_data[index2][0][k][0] = int(_joint_data[index2][0][k][0] / height * heatmap_height)\n",
    "                    _joint_data[index2][0][k][1] = int(_joint_data[index2][0][k][1] / width * heatmap_width)\n",
    "\n",
    "\n",
    "\n",
    "            index2 = index2 + 1\n",
    "\n",
    "        \n",
    "        return file_path2, _joint_data\n",
    "    \n",
    "        \n",
    "    \n",
    "def load_test_data():\n",
    "    img_path = \"./MPII_Dataset/resized_test_image/\"\n",
    "    file_path = []\n",
    "    file_list = os.listdir(img_path)\n",
    "    for i in (file_list):\n",
    "        file_path.append(img_path + i)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell end\n"
     ]
    }
   ],
   "source": [
    "class openpose():\n",
    "    def __init__(self, batch_size, sess):\n",
    "        self.sess = sess\n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, img_width, img_width, 3])\n",
    "        self.confidence_map_label = tf.placeholder(dtype=tf.float32, shape=[None, network_output, network_output, 17])\n",
    "        self.vector_map_label = tf.placeholder(dtype=tf.float32, shape=[None, network_output, network_output, 34])\n",
    "        self.batch_size = batch_size\n",
    "        print(\"test data load start\")\n",
    "        self.test_image_path = self.load_test_data()\n",
    "        print(\"test data load finish\")\n",
    "\n",
    "        self.model()\n",
    "        self.optimizer()\n",
    "        print(\"open pose init complete\")\n",
    "        \n",
    "    def load_test_data(self):\n",
    "        img_path = \"./MPII_Dataset/resized_test_image/\"\n",
    "        file_path = []\n",
    "        file_list = os.listdir(img_path)\n",
    "        for i in (file_list):\n",
    "            file_path.append(img_path + i)\n",
    "        return file_path\n",
    "        \n",
    "    \n",
    "    def make_heatmap(self, batch_anno_data, width = network_output, height = network_output, num_of_maps = 17):\n",
    "        batch_size = self.batch_size\n",
    "        width = network_output\n",
    "        height = network_output\n",
    "        num_of_maps = 17\n",
    "        output = np.zeros((batch_size, width, height, num_of_maps))\n",
    "        for index, joint_data in enumerate(batch_anno_data):\n",
    "\n",
    "            heatmap = np.zeros((width, height, num_of_maps), np.int16)#batch 일단 뺌\n",
    "\n",
    "            for joints in joint_data:\n",
    "                buffer = list(joints.items())\n",
    "                key_buffer = joints.keys()\n",
    "\n",
    "                for i in range(len(buffer)):\n",
    "                    buffer[i] = list(buffer[i])\n",
    "                    buffer[i][0] = int(buffer[i][0])\n",
    "                bubble_sort(buffer)\n",
    "\n",
    "                idx = 0\n",
    "                for j in range(17):\n",
    "\n",
    "                    #print(j)\n",
    "                    if('%d' %j in key_buffer):\n",
    "                        center_x = buffer[idx][1][0]\n",
    "                        center_y = buffer[idx][1][1]\n",
    "                        #joint = buffer[idx][1]\n",
    "                        joint = [center_y, center_x]\n",
    "                        idx = idx + 1\n",
    "                        _put_heatmap_on_plane(heatmap, plane_idx = j, joint = joint, sigma = 3, height = height, \\\n",
    "                                              width = width, stride = 1)\n",
    "                    else:\n",
    "                        pass\n",
    "                idx = 0\n",
    "            heatmap[:, :, -1] = np.clip(1.0 - np.amax(heatmap, axis=2), 0.0, 1.0)\n",
    "            output[index] = heatmap\n",
    "        return output\n",
    "        \n",
    "    \n",
    "    def make_paf_field(self, batch_joint_data, width = network_output, height = network_output, num_of_maps = 17):\n",
    "        batch_size = 16\n",
    "        output1 = np.zeros((batch_size, width, height, num_of_maps*2))\n",
    "        output2 = np.zeros((batch_size, width, height, num_of_maps))\n",
    "        for index, joint_data in enumerate(batch_joint_data):\n",
    "            joint_pairs = list(zip(\n",
    "                [9, 8, 8, 8,13,14,12,11,7,6,6,3,4,2,1],\n",
    "                [8,13,12, 7,14,15,11,10,6,3,2,4,5,1,0]))\n",
    "            #make vector map\n",
    "            width = network_output\n",
    "            height = network_output\n",
    "            num_of_maps = 17\n",
    "            vectormap = np.zeros((width, height, num_of_maps*2), dtype=np.float32)#batch 일단 뺌\n",
    "            countmap = np.zeros((width, height, num_of_maps), np.int16)#batch 일단 뺌\n",
    "\n",
    "            for joints in joint_data:\n",
    "                key = (joints.keys())\n",
    "                for plane_idx, (j_idx1, j_idx2) in enumerate(joint_pairs):\n",
    "                    if(('%d' %j_idx1 in key) and ('%d' %j_idx2 in key)):\n",
    "\n",
    "                        center_from = joints['%d'%j_idx1]\n",
    "                        center_to = joints['%d'%j_idx2]\n",
    "\n",
    "                        if not center_from or not center_to:\n",
    "                            continue\n",
    "                        _put_paf_on_plane(vectormap=vectormap, countmap=countmap, plane_idx=plane_idx, center_from=center_from, center_to=center_to, \\\n",
    "                                          threshold=1, height=network_output, width=network_output, stride = 1)\n",
    "\n",
    "            nonzeros = np.nonzero(countmap)\n",
    "\n",
    "\n",
    "            for x, y, p in zip(nonzeros[0], nonzeros[1], nonzeros[2]):\n",
    "                if countmap[x][y][p] <= 0:\n",
    "                    continue\n",
    "                vectormap[x][y][p*2+0] /= countmap[x][y][p]\n",
    "                vectormap[x][y][p*2+1] /= countmap[x][y][p]\n",
    "\n",
    "            output1[index] = vectormap.astype(np.float32)\n",
    "            output2[index] = countmap\n",
    "        return output1, output2 #output1 -> vectormap, output2 -> countmap\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def model(self):\n",
    "        stage0_data = net.block_vgg_19(self.X)#stage0_data - None, 58, 58, 512\n",
    "        \n",
    "        self.stage1_branch1 = net.block_stage_1_branch1(stage0_data)#stage1_branch1 - None, 58, 58, 34\n",
    "        self.stage1_branch2 = net.block_stage_1_branch2(stage0_data)#stage1_branch2 - None, 58, 58, 17\n",
    "        self.stage1_data = tf.concat([self.stage1_branch1, self.stage1_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage2_branch1 = net.block_stage_2_branch1(self.stage1_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage2_branch2 = net.block_stage_2_branch2(self.stage1_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage2_data = tf.concat([self.stage2_branch1, self.stage2_branch2, stage0_data], 3)\n",
    "\n",
    "        self.stage3_branch1 = net.block_stage_3_branch1(self.stage2_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage3_branch2 = net.block_stage_3_branch2(self.stage2_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage3_data = tf.concat([self.stage3_branch1, self.stage3_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage4_branch1 = net.block_stage_4_branch1(self.stage3_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage4_branch2 = net.block_stage_4_branch2(self.stage3_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage4_data = tf.concat([self.stage4_branch1, self.stage4_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage5_branch1 = net.block_stage_5_branch1(self.stage4_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage5_branch2 = net.block_stage_5_branch2(self.stage4_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage5_data = tf.concat([self.stage5_branch1, self.stage5_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage6_branch1 = net.block_stage_6_branch1(self.stage5_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage6_branch2 = net.block_stage_6_branch2(self.stage5_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage6_data = tf.concat([self.stage6_branch1, self.stage6_branch2, stage0_data], 3)\n",
    "\n",
    "    def optimizer(self):\n",
    "        \n",
    "        W_p = 1\n",
    "        #loss는 euclid loss 함수 사용\n",
    "        #affinity field loss - branch1\n",
    "        self.loss_stage1_branch1 = tf.nn.l2_loss(W_p*(self.stage1_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage2_branch1 = tf.nn.l2_loss(W_p*(self.stage2_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage3_branch1 = tf.nn.l2_loss(W_p*(self.stage3_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage4_branch1 = tf.nn.l2_loss(W_p*(self.stage4_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage5_branch1 = tf.nn.l2_loss(W_p*(self.stage5_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage6_branch1 = tf.nn.l2_loss(W_p*(self.stage6_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        \n",
    "        #confidence map loss - branch2\n",
    "        \n",
    "        self.loss_stage1_branch2 = tf.nn.l2_loss(W_p*(self.stage1_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage2_branch2 = tf.nn.l2_loss(W_p*(self.stage2_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage3_branch2 = tf.nn.l2_loss(W_p*(self.stage3_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage4_branch2 = tf.nn.l2_loss(W_p*(self.stage4_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage5_branch2 = tf.nn.l2_loss(W_p*(self.stage5_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage6_branch2 = tf.nn.l2_loss(W_p*(self.stage6_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        \n",
    "        self.loss1 = tf.reduce_mean([self.loss_stage1_branch1, self.loss_stage1_branch2])\n",
    "        self.loss2 = tf.reduce_mean([self.loss_stage2_branch1, self.loss_stage2_branch2])\n",
    "        self.loss3 = tf.reduce_mean([self.loss_stage3_branch1, self.loss_stage3_branch2])\n",
    "        self.loss4 = tf.reduce_mean([self.loss_stage4_branch1, self.loss_stage4_branch2])\n",
    "        self.loss5 = tf.reduce_mean([self.loss_stage5_branch1, self.loss_stage5_branch2])\n",
    "        self.loss6 = tf.reduce_mean([self.loss_stage6_branch1, self.loss_stage6_branch2])\n",
    "        \n",
    "        self.total_loss = (self.loss1 + self.loss2 + self.loss3 + self.loss4 + self.loss5 + self.loss6) / self.batch_size\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = 4e-5\n",
    "        lr = tf.train.exponential_decay(starter_learning_rate, global_step,100000, 0.333, staircase=True)\n",
    "        self.optimizer_total_loss = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.total_loss, global_step=global_step)\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        data_size = 28883#41749\n",
    "        batch_size = self.batch_size\n",
    "        total_batch = data_size//batch_size\n",
    "\n",
    "        h_loss_data = []\n",
    "        #h_loss_data2 = []\n",
    "        #h_loss_data3 = []\n",
    "        #h_loss_data4 = []\n",
    "        #h_loss_data5 = []\n",
    "        #h_loss_data6 = []\n",
    "        \n",
    "        v_loss_data = []\n",
    "        #v_loss_data2 = []\n",
    "        #v_loss_data3 = []\n",
    "        #v_loss_data4 = []\n",
    "        #v_loss_data5 = []\n",
    "        #v_loss_data6 = []\n",
    "        \n",
    "        SAVE_PATH = \"C:/Users/JAEKYU/Documents/Jupyter Notebook/Open_Pose/Weight/Weight.ckpt\"\n",
    "        print(\"session start\")\n",
    "        #with tf.Session() as sess:\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        print(\"training data load start\")\n",
    "        self.image_path, self.annotation_data = load_data()\n",
    "        print(\"training data load finish\")\n",
    "        try:\n",
    "            saver.restore(self.sess, SAVE_PATH)\n",
    "            print(\"load\")\n",
    "        except:\n",
    "            print(\"first training\")\n",
    "\n",
    "\n",
    "        for epoch in range(30):#15\n",
    "            print(\"epoch\",epoch+1, \"start\")\n",
    "            for i in range(total_batch):#total_batch\n",
    "                #data load, batch 생성\n",
    "                batch_img_path, batch_annotation= make_batch(img_path = self.image_path, anno_data = self.annotation_data, batch_size = batch_size)\n",
    "                batch_img = path_to_image(batch_img_path, batch_size)\n",
    "\n",
    "                #batch_img, batch_annotation - input data\n",
    "\n",
    "                heatmap = self.make_heatmap(batch_annotation, width=network_output, height=network_output, num_of_maps=17)\n",
    "                vectormap, countmap = self.make_paf_field(batch_annotation, width = network_output, height = network_output, num_of_maps = 17)\n",
    "\n",
    "                total_loss_opt, Heat_loss, Vector_loss = \\\n",
    "                self.sess.run([self.optimizer_total_loss, self.loss_stage6_branch1, self.loss_stage6_branch2],\n",
    "                         feed_dict = {self.X : batch_img, self.confidence_map_label : heatmap, self.vector_map_label : vectormap})\n",
    "\n",
    "                h_loss_data.append(Heat_loss)\n",
    "                v_loss_data.append(Vector_loss)\n",
    "\n",
    "            print(\"heatmap cost\")\n",
    "            print(\"Heat_loss : \", Heat_loss)\n",
    "            print(\"vectormap cost\")\n",
    "            print(\"Vector_loss : \", Vector_loss)\n",
    "            print('\\n')\n",
    "\n",
    "            plt.plot(h_loss_data)\n",
    "            plt.show()\n",
    "            plt.plot(v_loss_data)\n",
    "            plt.show()\n",
    "            saver.save(self.sess, SAVE_PATH)\n",
    "        #return batch_img, batch_img_path, batch_annotation, heatmap, vectormap, countmap\n",
    "        #return self.image_path, self.annotation_data\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def test(self):\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        SAVE_PATH = \"C:/Users/JAEKYU/Documents/Jupyter Notebook/Open_Pose/Weight/Weight.ckpt\"\n",
    "        print(\"session start\")\n",
    "        #with tf.Session() as sess:\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        saver.restore(self.sess, SAVE_PATH)\n",
    "        print(\"weight load\")\n",
    "\n",
    "        batch_img_path = make_test_batch(img_path = self.test_image_path, batch_size = batch_size)\n",
    "        print(\"1\")\n",
    "        batch_img = path_to_image(batch_img_path, batch_size)\n",
    "        print(\"2\")\n",
    "\n",
    "        #batch_img, batch_annotation - input data\n",
    "\n",
    "        #heatmap = self.make_heatmap(batch_annotation, width=44, height=44, num_of_maps=17)\n",
    "        #vectormap, countmap = self.make_paf_field(batch_annotation, width = 44, height = 44, num_of_maps = 17)\n",
    "\n",
    "        stage_output1, stage_output2, stage_output3, stage_output4, stage_output5, stage_output6 = \\\n",
    "        self.sess.run([self.stage1_branch2, self.stage2_branch2, self.stage3_branch2, self.stage4_branch2, self.stage5_branch2, self.stage6_branch2], \\\n",
    "                 feed_dict = {self.X : batch_img})\n",
    "        print(\"3\")\n",
    "        _stage_output1, _stage_output2, _stage_output3, _stage_output4, _stage_output5, _stage_output6 = \\\n",
    "        self.sess.run([self.stage1_branch1, self.stage2_branch1, self.stage3_branch1, self.stage4_branch1, self.stage5_branch1, self.stage6_branch1], \\\n",
    "                 feed_dict = {self.X : batch_img})\n",
    "        \n",
    "        return batch_img, batch_img_path, stage_output4, stage_output5, stage_output6, _stage_output4, _stage_output5, _stage_output6\n",
    "    \n",
    "    def demo_test(self, test_data):\n",
    "        #print(\"testing...\")\n",
    "        SAVE_PATH = \"C:/Users/JAEKYU/Documents/Jupyter Notebook/Open_Pose/Weight/Weight.ckpt\"\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        saver.restore(self.sess, SAVE_PATH)\n",
    "        print(\"weight load\")\n",
    "        \n",
    "        heatmap, vectormap = self.sess.run(self.stage6_branch2, self.stage6_branch1, feed_dict={self.X : test_data})\n",
    "        #predict = np.clip(predict, 0, 255).astype(np.uint8)\n",
    "        #print(predict)\n",
    "        #print(test_data)\n",
    "        #predict = np.array(predict)\n",
    "        #predict_buff = np.zeros((self.input_size, self.input_size, self.channel_dim))\n",
    "        #for row in range(self.input_size):\n",
    "        #    for col in range(self.input_size):\n",
    "        #        for channel in range(self.channel_dim):\n",
    "        #           predict_buff[row][col][channel] = -1 *  predict[0][row][col][channel]\n",
    "\n",
    "\n",
    "        #predict_buffer = predict.flatten()\n",
    "        #predict = predict_buffer.reshape(120, 120, 3)\n",
    "        #predict = misc.imresize(predict, (120, 120))#자동으로 (33x33)사이즈의 이미지가 됨\n",
    "        #plt.imshow(predict_buff)\n",
    "        #plt.show()\n",
    "        return heatmap, vectormap\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"cell end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data load start\n",
      "test data load finish\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 45 and 44 for 'sub' (op: 'Sub') with input shapes: [?,45,45,34], [?,44,44,34].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 45 and 44 for 'sub' (op: 'Sub') with input shapes: [?,45,45,34], [?,44,44,34].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c9fcfbf6cf32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopenpose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#batch_img, batch_img_path, stage_output4, \\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#stage_output5, stage_output6, _stage_output4, _stage_output5, _stage_output6 = obj.test()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-4cc93c487e5d>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_size, sess)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"open pose init complete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-4cc93c487e5d>\u001b[0m in \u001b[0;36moptimizer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m#loss는 euclid loss 함수 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;31m#affinity field loss - branch1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_stage1_branch1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_p\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage1_branch1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_map_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_stage2_branch1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_p\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage2_branch1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_map_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_stage3_branch1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW_p\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage3_branch1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_map_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    977\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 979\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   8580\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8581\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 8582\u001b[1;33m         \"Sub\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   8583\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8584\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3392\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1734\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1735\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 45 and 44 for 'sub' (op: 'Sub') with input shapes: [?,45,45,34], [?,44,44,34]."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    obj = openpose(batch_size=16, sess = sess)\n",
    "    #batch_img, batch_img_path, stage_output4, \\\n",
    "#stage_output5, stage_output6, _stage_output4, _stage_output5, _stage_output6 = obj.test()\n",
    "    obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    obj = openpose(batch_size=8, sess = sess)\n",
    "    batch_img, batch_img_path, stage_output4, \\\n",
    "stage_output5, stage_output6, _stage_output4, _stage_output5, _stage_output6 = obj.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(batch_img))\n",
    "test_index = 6\n",
    "buffer = batch_img[test_index][:,:,[2,1,0]]\n",
    "plt.imshow(buffer)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap\n",
    "np.shape(stage_output6)\n",
    "buffer = stage_output6[test_index]\n",
    "buffer = np.transpose(buffer, (2,0, 1))\n",
    "#resized_buffer = np.zeros((17, 356, 356))\n",
    "summed_buffer = np.zeros((44, 44))\n",
    "for i in range(17):\n",
    "    #resized_buffer[i] = cv2.resize(buffer[i], (356, 356))\n",
    "    plt.imshow(buffer[i])\n",
    "    plt.show()\n",
    "    \n",
    "#for i in range(17):\n",
    "#    for row in range(44):\n",
    "#        for col in range(44):\n",
    "#            if(buffer[i][row][col] < 0.7):\n",
    "#                buffer[i][row][col] = 0\n",
    "for i in range(17):\n",
    "    summed_buffer = summed_buffer + buffer[i]\n",
    "#summed_buffer = summed_buffer * 100\n",
    "print(\"summed_heatmap\")\n",
    "plt.imshow(summed_buffer)\n",
    "plt.show()\n",
    "summed_buffer\n",
    "print(np.shape(summed_buffer))\n",
    "#for row in range(44):\n",
    "#    for col in range(44):\n",
    "#        if(summed_buffer[row][col] < 1.0):\n",
    "#            summed_buffer[row][col] = 0\n",
    "summed_buffer = cv2.resize(summed_buffer, (356,356))\n",
    "summed_buffer\n",
    "cv2.imshow(\"image1\",summed_buffer)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "summed_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectormap\n",
    "np.shape(_stage_output6)\n",
    "buffer = _stage_output6[test_index]\n",
    "buffer = np.transpose(buffer, (2,0, 1))\n",
    "print(np.shape(buffer))\n",
    "#resized_buffer = np.zeros((34, 356, 356))\n",
    "summed_buffer = np.zeros((44, 44))\n",
    "for i in range(34):\n",
    "    #resized_buffer[i] = cv2.resize(buffer[i], (356, 356))\n",
    "    plt.imshow(buffer[i])\n",
    "    plt.show()\n",
    "#for i in range(34):\n",
    "#    for row in range(44):\n",
    "#        for col in range(44):\n",
    "#            if(buffer[i][row][col] < 0.5):\n",
    "#                buffer[i][row][col] = 0\n",
    "for i in range(34):\n",
    "    summed_buffer = summed_buffer + buffer[i]\n",
    "print(\"summed vectormap\")\n",
    "plt.imshow(summed_buffer)\n",
    "plt.show()\n",
    "\n",
    "summed_buffer = cv2.resize(summed_buffer, (356,356))\n",
    "cv2.imshow(\"image2\",summed_buffer)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "summed_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = countmap[3]\n",
    "oo2 = np.transpose(oo, (2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo3 = np.zeros((44, 44), dtype=np.float32)\n",
    "for i in range(17):\n",
    "    oo3 = oo3 + oo2[i]\n",
    "np.shape(oo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(oo3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_img, batch_img_path, batch_annotation, heatmap, \\\n",
    "stage_output1, stage_output2, stage_output3, stage_output4, stage_output5, stage_output6 = obj.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(stage_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 15\n",
    "_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = cv2.imshow('image', batch_img[test_index])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage Output을 transpose하여 526x526 사이즈로 resize 하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage output의 (32, 28, 28, 17)형태를 (32, 17, 28, 28)로 바꿈\n",
    "transposed_output = np.transpose(stage_output1, [0, 3, 1, 2])\n",
    "#for i in range(_batch_size):\n",
    "#    for j in range(17):\n",
    "#        for row in range(28):\n",
    "#            for col in range(28):\n",
    "#                if (transposed_output[i][j][row][col] < 0):\n",
    "#                    transposed_output[i][j][row][col] = 0\n",
    "\n",
    "\n",
    "\n",
    "resized_transposed_output = np.zeros((32, 17, 526, 526))\n",
    "for i in range(_batch_size):\n",
    "    for j in range(17):\n",
    "        resized_transposed_output[i][j] = cv2.resize(transposed_output[i][j], (526, 526))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap 0~17을 하나로 합치는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_ = np.zeros((32, 526, 526))\n",
    "\n",
    "for i in range(_batch_size):\n",
    "    for j in range(17):\n",
    "        merged_[i] = merged_[i] + resized_transposed_output[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합친 heatmap을 imshow 하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = cv2.imshow('image2', 5* merged_[test_index])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heatmap label 출력 해보는 부분(검증용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_heatmap = np.transpose(heatmap, [0, 3, 1, 2])\n",
    "resized_transposed_heatmap = np.zeros((32, 17, 526, 526))\n",
    "for i in range(_batch_size):\n",
    "    for j in range(17):\n",
    "        resized_transposed_heatmap[i][j] = cv2.resize(transposed_heatmap[i][j], (526, 526))\n",
    "merged_ = np.zeros((32, 526, 526))\n",
    "for i in range(_batch_size):\n",
    "    for j in range(17):\n",
    "        merged_[i] = merged_[i] + resized_transposed_heatmap[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = cv2.imshow('image2', merged_[test_index])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_from = [9, 8, 8, 8,13,14,12,11,7,6,6,3,4,2,1]#17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(joint_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyplot으로 test_index 의 이미지 heatmap 다 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage output의 (32, 28, 28, 17)형태를 (32, 17, 28, 28)로 바꿈\n",
    "transposed_output = np.transpose(stage_output, [0, 3, 1, 2])\n",
    "\n",
    "resized_transposed_output = np.zeros((32, 17, 526, 526))\n",
    "for j in range(_batch_size):\n",
    "    for i in range(17):\n",
    "        resized_transposed_output[j][i] = cv2.resize(transposed_output[j][i], (526, 526))\n",
    "        \n",
    "for idx in (17):\n",
    "    plt.imshow(resized_transposed_output[test_index][idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    path = \"./MPII_Dataset/annotation/mpii_human_pose_v1_u12_3.json\"\n",
    "    f = open(path)\n",
    "    s = f.readlines()\n",
    "\n",
    "    file_name = []\n",
    "    parts = []\n",
    "    _joint_data = []\n",
    "\n",
    "\n",
    "    img_path = \"./MPII_Dataset/images/\"\n",
    "    img_path2 = \"./MPII_Dataset/resize_images2/\"\n",
    "    file_path = []\n",
    "    file_path2 = []\n",
    "\n",
    "    for index, i in enumerate(s):\n",
    "\n",
    "        file_name_index = i.find(\"file_name\")\n",
    "        is_train_index = i.find(\"is_train\")\n",
    "        file_name.append(i[file_name_index + 13 :is_train_index - 4])\n",
    "\n",
    "\n",
    "        parts_index = i.find(\"parts\")\n",
    "        visibility_index = i.find(\"visibility\")\n",
    "        parts.append(i[parts_index + 8:visibility_index - 3])\n",
    "\n",
    "        joint_data = []\n",
    "        file_index, annotation_index = index, index\n",
    "        if(parts[index] == \"null\"):\n",
    "            joint_data.append(\"null\")\n",
    "            pass\n",
    "        else:\n",
    "            raw_data = ast.literal_eval(parts[annotation_index])\n",
    "            joint_data.append(raw_data)\n",
    "\n",
    "        _joint_data.append(joint_data)\n",
    "        index = index + 1\n",
    "    for i in file_name:\n",
    "        file_path.append(img_path + i)\n",
    "        file_path2.append(img_path2 + i)\n",
    "\n",
    "    index2 = 0\n",
    "    heatmap_height = 44\n",
    "    heatmap_width = 44\n",
    "    for j in file_path:\n",
    "        img_data = cv2.imread(j)\n",
    "        height = (np.shape(img_data)[0])\n",
    "        width = (np.shape(img_data)[1])\n",
    "\n",
    "        if(_joint_data[index2][0] == 'null'):\n",
    "            #print(_joint_data[index2][0])\n",
    "            pass\n",
    "        else:\n",
    "            array = _joint_data[index2][0].keys()\n",
    "            for k in array:\n",
    "                _joint_data[index2][0][k][0] = int(_joint_data[index2][0][k][0] / height * heatmap_height)\n",
    "                _joint_data[index2][0][k][1] = int(_joint_data[index2][0][k][1] / width * heatmap_width)\n",
    "\n",
    "\n",
    "\n",
    "        index2 = index2 + 1\n",
    "\n",
    "\n",
    "    return file_path2, _joint_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path, joint_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_img_path, batch_anno_data = make_batch(file_path, joint_data, batch_size = 8)\n",
    "batch_img_data = path_to_image(batch_img_path, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch 적용한 heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort(L):\n",
    "    for i in range(len(L)-1):\n",
    "        for j in range(len(L)-1):\n",
    "            if L[j] > L[j+1]:\n",
    "                temp = L[j+1]\n",
    "                L[j+1] = L[j]\n",
    "                L[j] = temp\n",
    "\n",
    "batch_size = 8\n",
    "width = 44\n",
    "height = 44\n",
    "num_of_maps = 17\n",
    "output = np.zeros((batch_size, width, height, num_of_maps))\n",
    "for index, joint_data in enumerate(batch_anno_data):\n",
    "\n",
    "    heatmap = np.zeros((width, height, num_of_maps), np.int16)#batch 일단 뺌\n",
    "\n",
    "    for joints in joint_data:\n",
    "        buffer = list(joints.items())\n",
    "        key_buffer = joints.keys()\n",
    "\n",
    "        for i in range(len(buffer)):\n",
    "            buffer[i] = list(buffer[i])\n",
    "            buffer[i][0] = int(buffer[i][0])\n",
    "        bubble_sort(buffer)\n",
    "\n",
    "        print(key_buffer)\n",
    "        print(buffer)\n",
    "        idx = 0\n",
    "        for j in range(17):\n",
    "            \n",
    "            #print(j)\n",
    "            if('%d' %j in key_buffer):\n",
    "                center_x = buffer[idx][1][0]\n",
    "                center_y = buffer[idx][1][1]\n",
    "                #joint = buffer[idx][1]\n",
    "                joint = [center_y, center_x]\n",
    "                idx = idx + 1\n",
    "                _put_heatmap_on_plane(heatmap, plane_idx = j, joint = joint, sigma = 0.3, height = height, \\\n",
    "                                      width = width, stride = 1)\n",
    "            else:\n",
    "                pass\n",
    "        idx = 0\n",
    "    heatmap[:, :, -1] = np.clip(1.0 - np.amax(heatmap, axis=2), 0.0, 1.0)\n",
    "    output[index] = heatmap\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(heatmap)\n",
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in range(17):\n",
    "test_index = 1\n",
    "print(batch_img_path[test_index])\n",
    "test_image = output[test_index]\n",
    "test_image = np.transpose(test_image, (2,0,1))\n",
    "#np.shape(test_image)\n",
    "ooo = np.zeros((58, 58))\n",
    "ooo2 = np.zeros((526, 526))\n",
    "for i in range(16):\n",
    "    ooo = ooo + test_image[i]\n",
    "    #plt.imshow(test_image[i])\n",
    "    #plt.show()\n",
    "ooo2 = cv2.resize(ooo, (526, 526))\n",
    "plt.imshow(ooo2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "batch 적용한 vectormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output1 = np.zeros((batch_size, width, height, num_of_maps*2))\n",
    "output2 = np.zeros((batch_size, width, height, num_of_maps))\n",
    "for index, joint_data in enumerate(batch_anno_data):\n",
    "    joint_pairs = list(zip(\n",
    "        [9, 8, 8, 8,13,14,12,11,7,6,6,3,4,2,1],\n",
    "        [8,13,12, 7,14,15,11,10,6,3,2,4,5,1,0]))\n",
    "    #make vector map\n",
    "    width = 58\n",
    "    height = 58\n",
    "    num_of_maps = 17\n",
    "    vectormap = np.zeros((width, height, num_of_maps*2), dtype=np.float32)#batch 일단 뺌\n",
    "    countmap = np.zeros((width, height, num_of_maps), np.int16)#batch 일단 뺌\n",
    "\n",
    "    for joints in joint_data:\n",
    "        key = (joints.keys())\n",
    "        for plane_idx, (j_idx1, j_idx2) in enumerate(joint_pairs):\n",
    "            if(('%d' %j_idx1 in key) and ('%d' %j_idx2 in key)):\n",
    "\n",
    "                center_from = joints['%d'%j_idx1]\n",
    "                center_to = joints['%d'%j_idx2]\n",
    "\n",
    "                if not center_from or not center_to:\n",
    "                    continue\n",
    "                _put_paf_on_plane(vectormap=vectormap, countmap=countmap, plane_idx=plane_idx, center_from=center_from, center_to=center_to, \\\n",
    "                                  threshold=1, height=58, width=58, stride = 1)\n",
    "\n",
    "    nonzeros = np.nonzero(countmap)\n",
    "\n",
    "\n",
    "    for x, y, p in zip(nonzeros[0], nonzeros[1], nonzeros[2]):\n",
    "        if countmap[x][y][p] <= 0:\n",
    "            continue\n",
    "        vectormap[x][y][p*2+0] /= countmap[x][y][p]\n",
    "        vectormap[x][y][p*2+1] /= countmap[x][y][p]\n",
    "\n",
    "    output1[index] = vectormap.astype(np.float32)\n",
    "    output2[index] = countmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.shape(output2))\n",
    "transposed_countmap = np.transpose(output2[3], [2, 0, 1])\n",
    "resized_countmap = np.zeros((17, 526, 526), dtype=np.float32)\n",
    "summed_countmap = np.zeros((526, 526), dtype=np.float32)\n",
    "for i in range(17):\n",
    "    resized_countmap[i] = cv2.resize(transposed_countmap[i], (526, 526))\n",
    "for j in range(17):\n",
    "    summed_countmap = summed_countmap + resized_countmap[j]\n",
    "\n",
    "plt.imshow(summed_countmap)\n",
    "plt.show()\n",
    "\n",
    "for i in range(17):\n",
    "    plt.imshow(resized_countmap[i])\n",
    "    plt.show()\n",
    "\n",
    "plt.imshow(resized_countmap[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./MPII_Dataset/test_image/\"\n",
    "file_path = []\n",
    "file_list = os.listdir(img_path)\n",
    "for i in (file_list):\n",
    "    file_path.append(img_path + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(file_list)\n",
    "#file_list[0]\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
