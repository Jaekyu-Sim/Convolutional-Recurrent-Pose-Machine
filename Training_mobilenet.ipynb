{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training-mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import ast\n",
    "import cv2\n",
    "import json\n",
    "import network as net\n",
    "import math\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(img_path, anno_data, batch_size = 16):\n",
    "    num_of_data = len(img_path)\n",
    "    index = np.arange(0, num_of_data)\n",
    "    np.random.shuffle(index)\n",
    "    index = index[:batch_size]\n",
    "    \n",
    "    shuffled_img_data = [img_path[i] for i in index]\n",
    "    shuffled_anno_data = [anno_data[j] for j in index]\n",
    "    \n",
    "    return np.asarray(shuffled_img_data), np.asarray(shuffled_anno_data)\n",
    "def make_test_batch(img_path, batch_size = 16):\n",
    "    num_of_data = len(img_path)\n",
    "    index = np.arange(0, num_of_data)\n",
    "    np.random.shuffle(index)\n",
    "    index = index[:batch_size]\n",
    "    \n",
    "    shuffled_img_data = [img_path[i] for i in index]\n",
    "    \n",
    "    return np.asarray(shuffled_img_data)\n",
    "\n",
    "def path_to_image(img_path, batch_size):\n",
    "    #buffer 선언\n",
    "    image_data = np.zeros((batch_size, 356, 356, 3), np.uint8)\n",
    "    \n",
    "    index = 0\n",
    "    for img in (img_path):\n",
    "        #buffer = cv2.imread(img)\n",
    "        #buffer = cv2.resize(buffer, (526, 526))\n",
    "        #image_data[index] = buffer\n",
    "        #index = index + 1\n",
    "        #buffer = cv2.resize(buffer, (526, 526))\n",
    "\n",
    "        image_data[index] = cv2.imread(img)\n",
    "        index = index + 1\n",
    "\n",
    "    return image_data\n",
    "\n",
    "def _put_heatmap_on_plane(heatmap, plane_idx, joint, sigma, height, width, stride):\n",
    "    start = stride / 2.0 - 0.5\n",
    "\n",
    "    center_x, center_y = joint\n",
    "\n",
    "    for g_y in range(height):\n",
    "        for g_x in range(width):\n",
    "            x = start + g_x * stride\n",
    "            y = start + g_y * stride\n",
    "            d2 = (x-center_x) * (x-center_x) + (y-center_y) * (y-center_y)\n",
    "            exponent = d2 / 2.0 / sigma / sigma\n",
    "            if exponent > 4.6052:\n",
    "                continue\n",
    "\n",
    "            heatmap[g_y, g_x, plane_idx] += math.exp(-exponent)\n",
    "            if heatmap[g_y, g_x, plane_idx] > 1.0:\n",
    "                heatmap[g_y, g_x, plane_idx] = 1.0\n",
    "                \n",
    "                \n",
    "def _put_paf_on_plane(vectormap, countmap, plane_idx, center_from, center_to, threshold, height, width, stride):\n",
    "    center_from = (center_from[0] // stride, center_from[1] // stride)\n",
    "    center_to = (center_to[0] // stride, center_to[1] // stride)\n",
    "\n",
    "    vec_x = center_to[0] - center_from[0]\n",
    "    vec_y = center_to[1] - center_from[1]\n",
    "\n",
    "    min_x = max(0, int(min(center_from[0], center_to[0]) - threshold))\n",
    "    min_y = max(0, int(min(center_from[1], center_to[1]) - threshold))\n",
    "\n",
    "    max_x = min(width, int(max(center_from[0], center_to[0]) + threshold))\n",
    "    max_y = min(height, int(max(center_from[1], center_to[1]) + threshold))\n",
    "\n",
    "    norm = math.sqrt(vec_x ** 2 + vec_y ** 2)\n",
    "    if norm < 1e-8: #1e-8 이하는 0으로 인식되서 0으로 나눌수 없다는 에러 발생. 따라서 return처리 해줌\n",
    "        return\n",
    "\n",
    "    vec_x /= norm\n",
    "    vec_y /= norm\n",
    "    \n",
    "    for x in range(min_x, max_x):\n",
    "        for y in range(min_y, max_y):\n",
    "            bec_x = x - center_from[0]\n",
    "            bec_y = y - center_from[1]\n",
    "            dist = abs(bec_x * vec_y - bec_y * vec_x)\n",
    "\n",
    "            if dist > threshold:\n",
    "                continue\n",
    "\n",
    "            countmap[x][y][plane_idx] = countmap[x][y][plane_idx] + 1\n",
    "\n",
    "            vectormap[x][y][plane_idx*2+0] = vec_x\n",
    "            vectormap[x][y][plane_idx*2+1] = vec_y\n",
    "            \n",
    "\n",
    "def bubble_sort(L):\n",
    "    for i in range(len(L)-1):\n",
    "        for j in range(len(L)-1):\n",
    "            if L[j] > L[j+1]:\n",
    "                temp = L[j+1]\n",
    "                L[j+1] = L[j]\n",
    "                L[j] = temp\n",
    "                \n",
    "def load_data():\n",
    "        path = \"./MPII_Dataset/annotation/mpii_human_pose_v1_u12_3.json\"\n",
    "        f = open(path)\n",
    "        s = f.readlines()\n",
    "\n",
    "        file_name = []\n",
    "        parts = []\n",
    "        _joint_data = []\n",
    "        \n",
    "        \n",
    "        img_path = \"./MPII_Dataset/images/\"#######\n",
    "        img_path2 = \"./MPII_Dataset/resized_images2/\"\n",
    "        file_path = []\n",
    "        file_path2 = []\n",
    "\n",
    "        for index, i in enumerate(s):\n",
    "\n",
    "            file_name_index = i.find(\"file_name\")\n",
    "            is_train_index = i.find(\"is_train\")\n",
    "            file_name.append(i[file_name_index + 13 :is_train_index - 4])\n",
    "\n",
    "\n",
    "            parts_index = i.find(\"parts\")\n",
    "            visibility_index = i.find(\"visibility\")\n",
    "            parts.append(i[parts_index + 8:visibility_index - 3])\n",
    "\n",
    "            joint_data = []\n",
    "            file_index, annotation_index = index, index\n",
    "            if(parts[index] == \"null\"):\n",
    "                joint_data.append(\"null\")\n",
    "                pass\n",
    "            else:\n",
    "                raw_data = ast.literal_eval(parts[annotation_index])\n",
    "                joint_data.append(raw_data)\n",
    "\n",
    "            _joint_data.append(joint_data)\n",
    "            index = index + 1\n",
    "        for i in file_name:\n",
    "            file_path.append(img_path + i)############\n",
    "            file_path2.append(img_path2 + i)\n",
    "\n",
    "        index2 = 0\n",
    "        heatmap_height = 45\n",
    "        heatmap_width = 45\n",
    "        for j in file_path:\n",
    "            img_data = cv2.imread(j)\n",
    "            height = (np.shape(img_data)[0])\n",
    "            width = (np.shape(img_data)[1])\n",
    "\n",
    "            if(_joint_data[index2][0] == 'null'):\n",
    "                #print(_joint_data[index2][0])\n",
    "                pass\n",
    "            else:\n",
    "                array = _joint_data[index2][0].keys()\n",
    "                for k in array:\n",
    "                    _joint_data[index2][0][k][0] = int(_joint_data[index2][0][k][0] / height * heatmap_height)\n",
    "                    _joint_data[index2][0][k][1] = int(_joint_data[index2][0][k][1] / width * heatmap_width)\n",
    "\n",
    "\n",
    "\n",
    "            index2 = index2 + 1\n",
    "\n",
    "        \n",
    "        return file_path2, _joint_data\n",
    "    \n",
    "        \n",
    "    \n",
    "def load_test_data():\n",
    "    img_path = \"./MPII_Dataset/resized_test_image/\"\n",
    "    file_path = []\n",
    "    file_list = os.listdir(img_path)\n",
    "    for i in (file_list):\n",
    "        file_path.append(img_path + i)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell end\n"
     ]
    }
   ],
   "source": [
    "class openpose_mobile():\n",
    "    def __init__(self, batch_size, sess):\n",
    "        self.sess = sess\n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, 356, 356, 3])\n",
    "        self.confidence_map_label = tf.placeholder(dtype=tf.float32, shape=[None, 45, 45, 17])\n",
    "        self.vector_map_label = tf.placeholder(dtype=tf.float32, shape=[None, 45, 45, 34])\n",
    "        self.batch_size = batch_size\n",
    "        print(\"test data load start\")\n",
    "        self.test_image_path = self.load_test_data()\n",
    "        print(\"test data load finish\")\n",
    "\n",
    "        self.model()\n",
    "        self.optimizer()\n",
    "        print(\"open pose mobilenet init complete\")\n",
    "        \n",
    "    def load_test_data(self):\n",
    "        img_path = \"./MPII_Dataset/resized_test_image/\"\n",
    "        file_path = []\n",
    "        file_list = os.listdir(img_path)\n",
    "        for i in (file_list):\n",
    "            file_path.append(img_path + i)\n",
    "        return file_path\n",
    "        \n",
    "    \n",
    "    def make_heatmap(self, batch_anno_data, width = 45, height = 45, num_of_maps = 17):\n",
    "        batch_size = self.batch_size\n",
    "        width = 45\n",
    "        height = 45\n",
    "        num_of_maps = 17\n",
    "        output = np.zeros((batch_size, width, height, num_of_maps))\n",
    "        for index, joint_data in enumerate(batch_anno_data):\n",
    "\n",
    "            heatmap = np.zeros((width, height, num_of_maps), np.int16)#batch 일단 뺌\n",
    "\n",
    "            for joints in joint_data:\n",
    "                buffer = list(joints.items())\n",
    "                key_buffer = joints.keys()\n",
    "\n",
    "                for i in range(len(buffer)):\n",
    "                    buffer[i] = list(buffer[i])\n",
    "                    buffer[i][0] = int(buffer[i][0])\n",
    "                bubble_sort(buffer)\n",
    "\n",
    "                idx = 0\n",
    "                for j in range(17):\n",
    "\n",
    "                    #print(j)\n",
    "                    if('%d' %j in key_buffer):\n",
    "                        center_x = buffer[idx][1][0]\n",
    "                        center_y = buffer[idx][1][1]\n",
    "                        #joint = buffer[idx][1]\n",
    "                        joint = [center_y, center_x]\n",
    "                        idx = idx + 1\n",
    "                        _put_heatmap_on_plane(heatmap, plane_idx = j, joint = joint, sigma = 3, height = height, \\\n",
    "                                              width = width, stride = 1)\n",
    "                    else:\n",
    "                        pass\n",
    "                idx = 0\n",
    "            heatmap[:, :, -1] = np.clip(1.0 - np.amax(heatmap, axis=2), 0.0, 1.0)\n",
    "            output[index] = heatmap\n",
    "        return output\n",
    "        \n",
    "    \n",
    "    def make_paf_field(self, batch_joint_data, width = 45, height = 45, num_of_maps = 17):\n",
    "        batch_size = 16\n",
    "        output1 = np.zeros((batch_size, width, height, num_of_maps*2))\n",
    "        output2 = np.zeros((batch_size, width, height, num_of_maps))\n",
    "        for index, joint_data in enumerate(batch_joint_data):\n",
    "            joint_pairs = list(zip(\n",
    "                [9, 8, 8, 8,13,14,12,11,7,6,6,3,4,2,1],\n",
    "                [8,13,12, 7,14,15,11,10,6,3,2,4,5,1,0]))\n",
    "            #make vector map\n",
    "            width = 45\n",
    "            height = 45\n",
    "            num_of_maps = 17\n",
    "            vectormap = np.zeros((width, height, num_of_maps*2), dtype=np.float32)#batch 일단 뺌\n",
    "            countmap = np.zeros((width, height, num_of_maps), np.int16)#batch 일단 뺌\n",
    "\n",
    "            for joints in joint_data:\n",
    "                key = (joints.keys())\n",
    "                for plane_idx, (j_idx1, j_idx2) in enumerate(joint_pairs):\n",
    "                    if(('%d' %j_idx1 in key) and ('%d' %j_idx2 in key)):\n",
    "\n",
    "                        center_from = joints['%d'%j_idx1]\n",
    "                        center_to = joints['%d'%j_idx2]\n",
    "\n",
    "                        if not center_from or not center_to:\n",
    "                            continue\n",
    "                        _put_paf_on_plane(vectormap=vectormap, countmap=countmap, plane_idx=plane_idx, center_from=center_from, center_to=center_to, \\\n",
    "                                          threshold=1, height=45, width=45, stride = 1)\n",
    "\n",
    "            nonzeros = np.nonzero(countmap)\n",
    "\n",
    "\n",
    "            for x, y, p in zip(nonzeros[0], nonzeros[1], nonzeros[2]):\n",
    "                if countmap[x][y][p] <= 0:\n",
    "                    continue\n",
    "                vectormap[x][y][p*2+0] /= countmap[x][y][p]\n",
    "                vectormap[x][y][p*2+1] /= countmap[x][y][p]\n",
    "\n",
    "            output1[index] = vectormap.astype(np.float32)\n",
    "            output2[index] = countmap\n",
    "        return output1, output2 #output1 -> vectormap, output2 -> countmap\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    def model(self):\n",
    "        stage0_data = net.mobilenet(self.X)#stage0_data - None, 58, 58, 512\n",
    "        \n",
    "        self.stage1_branch1 = net.block_stage_1_branch1(stage0_data)#stage1_branch1 - None, 58, 58, 34\n",
    "        self.stage1_branch2 = net.block_stage_1_branch2(stage0_data)#stage1_branch2 - None, 58, 58, 17\n",
    "        self.stage1_data = tf.concat([self.stage1_branch1, self.stage1_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage2_branch1 = net.block_stage_2_branch1(self.stage1_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage2_branch2 = net.block_stage_2_branch2(self.stage1_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage2_data = tf.concat([self.stage2_branch1, self.stage2_branch2, stage0_data], 3)\n",
    "\n",
    "        self.stage3_branch1 = net.block_stage_3_branch1(self.stage2_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage3_branch2 = net.block_stage_3_branch2(self.stage2_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage3_data = tf.concat([self.stage3_branch1, self.stage3_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage4_branch1 = net.block_stage_4_branch1(self.stage3_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage4_branch2 = net.block_stage_4_branch2(self.stage3_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage4_data = tf.concat([self.stage4_branch1, self.stage4_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage5_branch1 = net.block_stage_5_branch1(self.stage4_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage5_branch2 = net.block_stage_5_branch2(self.stage4_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage5_data = tf.concat([self.stage5_branch1, self.stage5_branch2, stage0_data], 3)\n",
    "        \n",
    "        self.stage6_branch1 = net.block_stage_6_branch1(self.stage5_data)#stage2_branch1 - None, 58, 58, 34\n",
    "        self.stage6_branch2 = net.block_stage_6_branch2(self.stage5_data)#stage2_branch2 - None, 58, 58, 17\n",
    "        self.stage6_data = tf.concat([self.stage6_branch1, self.stage6_branch2, stage0_data], 3)\n",
    "\n",
    "    def optimizer(self):\n",
    "        \n",
    "        W_p = 1\n",
    "        #loss는 euclid loss 함수 사용\n",
    "        #affinity field loss - branch1\n",
    "        self.loss_stage1_branch1 = tf.nn.l2_loss(W_p*(self.stage1_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage2_branch1 = tf.nn.l2_loss(W_p*(self.stage2_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage3_branch1 = tf.nn.l2_loss(W_p*(self.stage3_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage4_branch1 = tf.nn.l2_loss(W_p*(self.stage4_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage5_branch1 = tf.nn.l2_loss(W_p*(self.stage5_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        self.loss_stage6_branch1 = tf.nn.l2_loss(W_p*(self.stage6_branch1 - self.vector_map_label)) / self.batch_size\n",
    "        \n",
    "        #self.optimizer_stage1_branch1 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage1_branch1)\n",
    "        #self.optimizer_stage2_branch1 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage2_branch1)\n",
    "        #self.optimizer_stage3_branch1 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage3_branch1)\n",
    "        #self.optimizer_stage4_branch1 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage4_branch1)\n",
    "        #self.optimizer_stage5_branch1 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage5_branch1)\n",
    "        #self.optimizer_stage6_branch1 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage6_branch1)\n",
    "        \n",
    "        #confidence map loss - branch2\n",
    "        \n",
    "        self.loss_stage1_branch2 = tf.nn.l2_loss(W_p*(self.stage1_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage2_branch2 = tf.nn.l2_loss(W_p*(self.stage2_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage3_branch2 = tf.nn.l2_loss(W_p*(self.stage3_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage4_branch2 = tf.nn.l2_loss(W_p*(self.stage4_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage5_branch2 = tf.nn.l2_loss(W_p*(self.stage5_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        self.loss_stage6_branch2 = tf.nn.l2_loss(W_p*(self.stage6_branch2 - self.confidence_map_label)) / self.batch_size\n",
    "        \n",
    "        #self.optimizer_stage1_branch2 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage1_branch2)\n",
    "        #self.optimizer_stage2_branch2 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage2_branch2)\n",
    "        #self.optimizer_stage3_branch2 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage3_branch2)\n",
    "        #self.optimizer_stage4_branch2 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage4_branch2)\n",
    "        #self.optimizer_stage5_branch2 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage5_branch2)\n",
    "        #self.optimizer_stage6_branch2 = tf.train.AdamOptimizer(learning_rate=1e-6).minimize(self.loss_stage6_branch2)\n",
    "        \n",
    "        self.loss1 = tf.reduce_mean([self.loss_stage1_branch1, self.loss_stage1_branch2])\n",
    "        self.loss2 = tf.reduce_mean([self.loss_stage2_branch1, self.loss_stage2_branch2])\n",
    "        self.loss3 = tf.reduce_mean([self.loss_stage3_branch1, self.loss_stage3_branch2])\n",
    "        self.loss4 = tf.reduce_mean([self.loss_stage4_branch1, self.loss_stage4_branch2])\n",
    "        self.loss5 = tf.reduce_mean([self.loss_stage5_branch1, self.loss_stage5_branch2])\n",
    "        self.loss6 = tf.reduce_mean([self.loss_stage6_branch1, self.loss_stage6_branch2])\n",
    "        \n",
    "        self.total_loss = (self.loss1 + self.loss2 + self.loss3 + self.loss4 + self.loss5 + self.loss6) / self.batch_size\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        starter_learning_rate = 4e-5\n",
    "        lr = tf.train.exponential_decay(starter_learning_rate, global_step,100000, 0.333, staircase=True)\n",
    "        self.optimizer_total_loss = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.total_loss, global_step=global_step)\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        data_size = 28883#41749\n",
    "        batch_size = self.batch_size\n",
    "        total_batch = data_size//batch_size\n",
    "\n",
    "        h_loss_data = []\n",
    "        #h_loss_data2 = []\n",
    "        #h_loss_data3 = []\n",
    "        #h_loss_data4 = []\n",
    "        #h_loss_data5 = []\n",
    "        #h_loss_data6 = []\n",
    "        \n",
    "        v_loss_data = []\n",
    "        #v_loss_data2 = []\n",
    "        #v_loss_data3 = []\n",
    "        #v_loss_data4 = []\n",
    "        #v_loss_data5 = []\n",
    "        #v_loss_data6 = []\n",
    "        \n",
    "        SAVE_PATH = \"C:/Users/JAEKYU/Documents/Jupyter Notebook/Open_Pose/Weight_mobile/Weight.ckpt\"\n",
    "        print(\"session start\")\n",
    "        #with tf.Session() as sess:\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        print(\"training data load start\")\n",
    "        self.image_path, self.annotation_data = load_data()\n",
    "        print(\"training data load finish\")\n",
    "        try:\n",
    "            saver.restore(self.sess, SAVE_PATH)\n",
    "            print(\"load\")\n",
    "        except:\n",
    "            print(\"first training\")\n",
    "\n",
    "\n",
    "        for epoch in range(10):#15\n",
    "            print(\"epoch\",epoch+1, \"start\")\n",
    "            for i in range(total_batch):#total_batch\n",
    "                #data load, batch 생성\n",
    "                batch_img_path, batch_annotation= make_batch(img_path = self.image_path, anno_data = self.annotation_data, batch_size = batch_size)\n",
    "                batch_img = path_to_image(batch_img_path, batch_size)\n",
    "\n",
    "                #batch_img, batch_annotation - input data\n",
    "\n",
    "                heatmap = self.make_heatmap(batch_annotation, width=45, height=45, num_of_maps=17)\n",
    "                vectormap, countmap = self.make_paf_field(batch_annotation, width = 45, height = 45, num_of_maps = 17)\n",
    "\n",
    "                total_loss_opt, Heat_loss, Vector_loss = \\\n",
    "                self.sess.run([self.optimizer_total_loss, self.loss_stage6_branch1, self.loss_stage6_branch2],\n",
    "                         feed_dict = {self.X : batch_img, self.confidence_map_label : heatmap, self.vector_map_label : vectormap})\n",
    "\n",
    "\n",
    "                #__1, __2, __3, __4, __5, __6, v_cost1, v_cost2, v_cost3, v_cost4, v_cost5, v_cost6 = \\\n",
    "                #sess.run([self.optimizer_stage1_branch1, self.optimizer_stage2_branch1, self.optimizer_stage3_branch1, \\\n",
    "                #          self.optimizer_stage4_branch1, self.optimizer_stage5_branch1, self.optimizer_stage6_branch1, \\\n",
    "                #          self.loss_stage1_branch1, self.loss_stage2_branch1, self.loss_stage3_branch1, \\\n",
    "                #          self.loss_stage4_branch1, self.loss_stage5_branch1, self.loss_stage6_branch1], \\\n",
    "                #         feed_dict = {self.X : batch_img, self.vector_map_label : vectormap})\n",
    "\n",
    "                #_, cost, stage_output = sess.run([self.optimizer_stage1_branch2, self.loss_stage1_branch2, self.stage1_branch2], feed_dict = {self.X : batch_img, self.confidence_map_label : heatmap})\n",
    "                #session 돌리는 부분, run(optimizer)\n",
    "                #print(\"1 end\")\n",
    "                h_loss_data.append(Heat_loss)\n",
    "                #h_loss_data2.append(h_cost2)\n",
    "                #h_loss_data3.append(h_cost3)\n",
    "                #h_loss_data4.append(h_cost4)\n",
    "                #h_loss_data5.append(h_cost5)\n",
    "                #h_loss_data6.append(h_cost6)\n",
    "                #print(\"2 end\")\n",
    "                v_loss_data.append(Vector_loss)\n",
    "                #v_loss_data2.append(v_cost2)\n",
    "                #v_loss_data3.append(v_cost3)\n",
    "                #v_loss_data4.append(v_cost4)\n",
    "                #v_loss_data5.append(v_cost5)\n",
    "                #v_loss_data6.append(v_cost6)                    \n",
    "                #print(\"3 end\")\n",
    "                #print(\"iteration end\")\n",
    "            print(\"heatmap cost\")\n",
    "            print(\"Heat_loss : \", Heat_loss)\n",
    "            print(\"vectormap cost\")\n",
    "            print(\"Vector_loss : \", Vector_loss)\n",
    "            print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "            plt.plot(h_loss_data)\n",
    "            plt.show()\n",
    "            plt.plot(v_loss_data)\n",
    "            plt.show()\n",
    "            saver.save(self.sess, SAVE_PATH)\n",
    "        #return batch_img, batch_img_path, batch_annotation, heatmap, vectormap, countmap\n",
    "        #return self.image_path, self.annotation_data\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def test(self):\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        SAVE_PATH = \"C:/Users/JAEKYU/Documents/Jupyter Notebook/Open_Pose/Weight_mobile/Weight.ckpt\"\n",
    "        print(\"session start\")\n",
    "        #with tf.Session() as sess:\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        saver.restore(self.sess, SAVE_PATH)\n",
    "        print(\"weight load\")\n",
    "\n",
    "        batch_img_path = make_test_batch(img_path = self.test_image_path, batch_size = batch_size)\n",
    "        print(\"1\")\n",
    "        batch_img = path_to_image(batch_img_path, batch_size)\n",
    "        print(\"2\")\n",
    "\n",
    "        #batch_img, batch_annotation - input data\n",
    "\n",
    "        #heatmap = self.make_heatmap(batch_annotation, width=45, height=45, num_of_maps=17)\n",
    "        #vectormap, countmap = self.make_paf_field(batch_annotation, width = 45, height = 45, num_of_maps = 17)\n",
    "\n",
    "        stage_output1, stage_output2, stage_output3, stage_output4, stage_output5, stage_output6 = \\\n",
    "        self.sess.run([self.stage1_branch2, self.stage2_branch2, self.stage3_branch2, self.stage4_branch2, self.stage5_branch2, self.stage6_branch2], \\\n",
    "                 feed_dict = {self.X : batch_img})\n",
    "        print(\"3\")\n",
    "        _stage_output1, _stage_output2, _stage_output3, _stage_output4, _stage_output5, _stage_output6 = \\\n",
    "        self.sess.run([self.stage1_branch1, self.stage2_branch1, self.stage3_branch1, self.stage4_branch1, self.stage5_branch1, self.stage6_branch1], \\\n",
    "                 feed_dict = {self.X : batch_img})\n",
    "        \n",
    "        return batch_img, batch_img_path, stage_output4, stage_output5, stage_output6, _stage_output4, _stage_output5, _stage_output6\n",
    "    \n",
    "    def demo_test(self, test_data):\n",
    "        #print(\"testing...\")\n",
    "        SAVE_PATH = \"C:/Users/JAEKYU/Documents/Jupyter Notebook/Open_Pose/Weight_mobile/Weight.ckpt\"\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        saver.restore(self.sess, SAVE_PATH)\n",
    "        print(\"weight load\")\n",
    "        \n",
    "        heatmap, vectormap = self.sess.run(self.stage6_branch2, self.stage6_branch1, feed_dict={self.X : test_data})\n",
    "        #predict = np.clip(predict, 0, 255).astype(np.uint8)\n",
    "        #print(predict)\n",
    "        #print(test_data)\n",
    "        #predict = np.array(predict)\n",
    "        #predict_buff = np.zeros((self.input_size, self.input_size, self.channel_dim))\n",
    "        #for row in range(self.input_size):\n",
    "        #    for col in range(self.input_size):\n",
    "        #        for channel in range(self.channel_dim):\n",
    "        #           predict_buff[row][col][channel] = -1 *  predict[0][row][col][channel]\n",
    "\n",
    "\n",
    "        #predict_buffer = predict.flatten()\n",
    "        #predict = predict_buffer.reshape(120, 120, 3)\n",
    "        #predict = misc.imresize(predict, (120, 120))#자동으로 (33x33)사이즈의 이미지가 됨\n",
    "        #plt.imshow(predict_buff)\n",
    "        #plt.show()\n",
    "        return heatmap, vectormap\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"cell end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data load start\n",
      "test data load finish\n",
      "net's shape :  (?, 45, 45, 512)\n",
      "open pose mobilenet init complete\n",
      "session start\n",
      "training data load start\n",
      "training data load finish\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/JAEKYU/Documents/Jupyter Notebook/Open_Pose/Weight_mobile/Weight.ckpt\n",
      "first training\n",
      "epoch 1 start\n",
      "heatmap cost\n",
      "Heat_loss :  87.18658\n",
      "vectormap cost\n",
      "Vector_loss :  14.529922\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24bea32d240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24dfaa2e710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-22a6f54b5bf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#batch_img, batch_img_path, stage_output4, \\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#stage_output5, stage_output6, _stage_output4, _stage_output5, _stage_output6 = obj.test()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-1ed734e82dc5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;31m#batch_img, batch_annotation - input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                 \u001b[0mheatmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_annotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_maps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m                 \u001b[0mvectormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcountmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_paf_field\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_annotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_maps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1ed734e82dc5>\u001b[0m in \u001b[0;36mmake_heatmap\u001b[1;34m(self, batch_anno_data, width, height, num_of_maps)\u001b[0m\n\u001b[0;32m     52\u001b[0m                         \u001b[0mjoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcenter_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter_x\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                         \u001b[0m_put_heatmap_on_plane\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplane_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m                                               \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-aea18cbd032e>\u001b[0m in \u001b[0;36m_put_heatmap_on_plane\u001b[1;34m(heatmap, plane_idx, joint, sigma, height, width, stride)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mg_y\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mg_x\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mg_x\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mg_y\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0md2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter_x\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter_x\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcenter_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    obj = openpose_mobile(batch_size=16, sess = sess)\n",
    "    #batch_img, batch_img_path, stage_output4, \\\n",
    "    #stage_output5, stage_output6, _stage_output4, _stage_output5, _stage_output6 = obj.test()\n",
    "    obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
